{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc7b370",
   "metadata": {},
   "source": [
    "# Carga de dados\n",
    "Há diferentes formas de se fazer carga de dados e aqui discutiremos duas estratégias diferentes, muito importantes e difundidas.\n",
    "\n",
    "## Batch\n",
    "Cargas feitas em formato de batch, ou lotes, implicam em acumulo de dados durante um período de tempo determinado para então processá-los.\n",
    "\n",
    "Dentro deste formato encontram-se muitos ambientes de BI tradicionais, onde sistemas OLTP produzem e coletam dados durante o dia, para em janelas noturas acontecerem as extrações, transformações e cargas (ETL). Um fluxo como este de exemplo, tem como produto um Data Warehouse D-1, ou seja, com atraso de um dia das informações ali disponíveis para análises.\n",
    "\n",
    "## Streaming\n",
    "Streaming por sua vez parte do pressuposto que datasets podem ser infinitos, e diferente dos batchs que aguardam janelas de execução e acumulam dados enquanto isso, neste modelo os dados são processados assim que disponibilizados, em tempo real ou o mais próximo disso possível.\n",
    "\n",
    "O Kafka é o ferramenta que permite que isto seja possível, como visualizado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3429176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "430f80ee",
   "metadata": {},
   "source": [
    "# Kafka\n",
    "Apache Kafka é uma plataforma de streaming de eventos distribuída de código aberto desenvolvida em Scala e Java e usada para pipelines de dados de alto desempenho, análise de streaming e integração de dados.\n",
    "\n",
    "Tem como objetivo fornecer uma  plataforma unificada, de alta capacidade e baixa latência para tratamento de dados em tempo real. Sua camada de armazenamento é, essencialmente, uma \"fila de mensagens de publishers/subscribers maciçamente escalável projetada como um log de transações distribuído\" tornando-o altamente valioso para infra-estruturas corporativas que processam transmissão de dados.\n",
    "\n",
    "A fim de tornar a solução ainda mais poderosa e complexa, é possível utilizá-la em conjunto com outras ferramentas de ingestão como o Apache Flume e o Spark Streaming.\n",
    "\n",
    "## Características\n",
    "- Plataforma de streaming distribuída.\n",
    "- Permite publish e subscribe de streams semelhante a uma fila de mensagens.\n",
    "- Tolerante a falhas.\n",
    "- Real Time.\n",
    "- Trabalha em cluster com um ou mais nós.\n",
    "- Suporta milhões de mensagens por segundo.\n",
    "- Entrega de mensagens de baixa latência.\n",
    "- Suporta múltiplos clientes como Java, .NET, PHP, Ruby, python.\n",
    "- Escrita e leitura em memória .\n",
    "- Persiste todos os dados no disco.\n",
    "- Integração nativa com Storm, Spark Streaming e Flume.\n",
    "- Escalável.\n",
    "\n",
    "## Arquitetura\n",
    "O Kafka é usado com mais frequência para transmitir dados em real time para outros sistemas. Kafka é uma camada intermediária para desacoplar seus pipelines de dados em real time.\n",
    "\n",
    "O core Kafka não é bom para cálculos diretos, como agregações de dados. O streaming Kafka, que faz parte do ecossistema Kafka, fornece a capacidade de fazer análises em tempo real.\n",
    "\n",
    "![Arquitetura](https://s3-sa-east-1.amazonaws.com/lcpi/78ec5e5c-ee59-4466-b1dd-1a9beffc4720.png)\n",
    "\n",
    "## Kafka API\n",
    "![API](https://s3-sa-east-1.amazonaws.com/lcpi/3cfe3dbc-9384-4a5e-8e99-0718907dbfc3.png)\n",
    "\n",
    "## Tópico\n",
    "O tópico é um canal lógico no qual os producer publicam mensagens e dos quais os consumer recebem mensagens.\n",
    "\n",
    "- Onde os dados são armazenados.\n",
    "- São armazenados em logs.\n",
    "- São multi-assinantes, podendo ter zero, um ou muitos - consumidores.\n",
    "- São divididos em partições.\n",
    "- Os registros publicados no tópico são retidos por um período configurável de tempo.\n",
    "\n",
    "## Partição\n",
    "Em um cluster Kafka, os Tópicos são divididos em Partições e também replicados entre os intermediários.\n",
    "\n",
    "- Cada partição é uma sequência ordenada e imutável de registros que é anexado continuamente a um log de confirmação estruturado.\n",
    "- Os registros nas partições recebem cada um um número de identificação sequencial chamado offset que identifica de forma exclusiva cada registro dentro da partição.\n",
    "- São distribuídas pelos servidores no cluster Kafka. \n",
    "- É replicada em um número configurável de servidores para tolerância a falha.\n",
    "\n",
    "## Kafka Broker\n",
    "- Kafka Cluster possui vários Broker (Instância de Kafka) e se houver mais de um temos um Cluster Kafka.\n",
    "- Cada Broker pode ter zero ou mais partições por tópico.\n",
    "Mantém o equilíbrio da carga.\n",
    "- São stateless, usam o ZooKeeper para manter seu estado no cluster.\n",
    "- Um Broker pode lidar com centenas de milhares de leituras e gravações por segundo e TB de mensagens sem perder desempenho.\n",
    "\n",
    "### Producer\n",
    "Permite que um aplicativo publique registros nos tópicos.\n",
    "\n",
    "- Envia os dados para os Brokers.\n",
    "- Escolhe em qual tópico o dados vai ser escrito.\n",
    "- Quando um novo Broker é iniciado, todos os producers enviam - uma mensagem para ele.\n",
    "- Producer não aguarda OK do Broker, envia as mensagens rapidamente para o Broker.\n",
    "\n",
    "### Consumer\n",
    "Permite que um aplicativo se inscreva em um ou mais tópicos e processe os registro.\n",
    "\n",
    "- Lêem os dados do Broker.\n",
    "- Assinam um ou mais tópicos e consomem as mensagens publicadas.\n",
    "- Tem o controle das mensagens que foram consumidas usando o offset da partição.\n",
    "- Emite uma solicitação de offset assíncrona ao Broker para ter um buffer de bytes pronto para consumir.\n",
    "\n",
    "## ZooKeeper\n",
    "O Kafka broker usa o ZooKeeper visando gerenciamento e coordenação. Além disso, o utiliza para notificar o producer e o consumer sobre a presença de qualquer novo evento no sistema do Kafka ou falha no sistema. Assim que o tratador envia a notificação ou falha sobre producer e consumer, toma a decisão e começa a coordenar sua tarefa com outro broker.\n",
    "\n",
    "### Características\n",
    "- Parte importante de um Cluster Kafka.\n",
    "- Coordenação entre os Brokers e os Consumers.\n",
    "- Cluster Kafka compartilha informações através de um cluster Zookeeper.\n",
    "- Kafka armazena metadados básicos no Zookeeper.\n",
    "- Utilizado para fazer eleição de liderança dos Brokers e partições.\n",
    "- Fornece uma visão sincronizada da configuração do Kafka Cluster.\n",
    "\n",
    "## Fator de replicação\n",
    "Ao projetar um sistema Kafka, é sempre uma decisão sábia levar em consideração a replicação de tópicos. Como resultado, as réplicas de seus tópicos de outro brokers podem resolver a crise se um broker cair. Por exemplo, temos 3 corretores e 3 tópicos. O Broker 1 possui o Tópico 1 e a Partição 0, sua réplica está no Broker 2, e assim por diante. Possui um fator de replicação 2; significa que ele terá uma cópia adicional diferente da primária. Abaixo está a imagem do fator de replicação de tópicos:\n",
    "\n",
    "![Replicacao](https://s3-sa-east-1.amazonaws.com/lcpi/53e59182-dd01-40ad-8c03-14c1098c4f55.jpeg)\n",
    "\n",
    "### Características\n",
    "- Armazena os dados em disco.\n",
    "- Por padrão são armazenados 7 dias.\n",
    "- Aṕos expiração as mensagens são excluídas automaticamente .\n",
    "- Configuração por tópico.\n",
    "- Cleanup também por espaço.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INtervalo. VOltamos 17:09!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c055e",
   "metadata": {},
   "source": [
    "# Prática\n",
    "Para a demonstração a seguir, o [Kafka 2.12-2.80](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.8.0/kafka_2.12-2.8.0.tgz) foi baixado e descompactado na `pasta D:`, em sistema operacional Microsoft Windows. É recomendado que todos comandos executados em prompts de comando sejam feitos tendo-os inciados em modo administrador.\n",
    "\n",
    "Primeiramente, crie dentro da pasta do kafka um diretório `data`, e dentro dele as pastas `kafka` e `zookeeper`.\n",
    "\n",
    "O segundo passo é apontar estes diretórios criados nas configurações do Kafka. Navegue até a pasta `config` e edite os arquivos `server` e `zookeper` da seguinte forma:\n",
    "\n",
    "    kafka -> log.dirs=D:/kafka_2.12-2.8.0/data/kafka\n",
    "    zookeeper -> dataDir=D:/kafka_2.12-2.8.0/data/zookeeper\n",
    "\n",
    "\n",
    "## Iniciando Zookeper\n",
    "No terminal:\n",
    "\n",
    "    D:\\kafka_2.12-2.8.0\\bin\\windows\\zookeeper-server-start D:\\kafka_2.12-2.8.0\\config\\zookeeper.properties\n",
    "    \n",
    "\n",
    "- Error: missing 'server' JVM at 'D:\\Program Files (x86)\\Java\\jre1.8.0_301\\bin\\server\\jvm.dll'.\n",
    "- [Solution](https://myfusion.blogspot.com/2016/11/missing-server-jvm-at-cprogram-files.html)\n",
    "\n",
    "\n",
    "## Iniciando Kafka\n",
    "Em outro terminal:\n",
    "\n",
    "    D:\\kafka_2.12-2.8.0\\bin\\windows\\kafka-server-start D:\\kafka_2.12-2.8.0\\config\\server.properties\n",
    "\n",
    "\n",
    "## Criando tópicos\n",
    "    \n",
    "    D:\\kafka_2.12-2.8.0\\bin\\windows\\kafka-topics --bootstrap-server localhost:9092 --create --topic aula_785\n",
    "    \n",
    "\n",
    "## Listando tópicos\n",
    "\n",
    "     D:\\kafka_2.12-2.8.0\\bin\\windows\\kafka-topics --bootstrap-server localhost:9092 --list\n",
    "     \n",
    "\n",
    "\n",
    "## Producer\n",
    "Abra um novo terminal para abrirmos o console do producer, aquele que produz as mensagens.\n",
    "\n",
    "    D:\\kafka_2.12-2.8.0\\bin\\windows\\kafka-console-producer --broker-list localhost:9092 --topic aula_785\n",
    "    \n",
    "\n",
    "## Consumer\n",
    "Em um novo terminal iniciaremos o consumer, que recebe as mesagens.\n",
    "\n",
    "    D:\\kafka_2.12-2.8.0\\bin\\windows\\kafka-console-consumer --bootstrap-server localhost:9092 --topic aula_785\n",
    "    \n",
    "\n",
    "## Simulando o funcionamento do streaming\n",
    "Insira mensagens no producer e veja como são imediatamente disponibilizadas no consumer.\n",
    "\n",
    "\n",
    "## Acessar mensagens anteriores\n",
    "\n",
    "Para ler todas mensagens já inseridas, execute:\n",
    "\n",
    "    D:\\kafka_2.12-2.8.0\\bin\\windows\\kafka-console-consumer --bootstrap-server localhost:9092 --topic aula_785 --from-beginning\n",
    "\n",
    "\n",
    "## Partições\n",
    "Descrever partição do tópico\n",
    "\n",
    "    D:\\kafka_2.12-2.8.0\\bin\\windows\\kafka-topics --bootstrap-server localhost:9092 --topic aula_785 --describe\n",
    "\n",
    "Alterar partição do tópico\n",
    "\n",
    "    D:\\kafka_2.12-2.8.0\\bin\\windows\\kafka-topics --bootstrap-server localhost:9092 --topic aula_785 --alter --partitions 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a49005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
