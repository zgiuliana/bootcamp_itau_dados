{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893f4d3d",
   "metadata": {},
   "source": [
    "# Aula 8 - Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e2f83",
   "metadata": {},
   "source": [
    "## Revisão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c054c00",
   "metadata": {},
   "source": [
    "### Acessar um tabela Hive via pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c41fb4",
   "metadata": {},
   "source": [
    "Criar o contexto `HiveContext`:\n",
    "\n",
    "    from pyspark.sql import HiveContext\n",
    "    contexto = HiveContext(sc)\n",
    "\n",
    "\n",
    "Conectar o banco de dados na tabela:\n",
    "\n",
    "    banco = contexto.table(\"hr.jobs\")\n",
    "    banco.show()\n",
    "\n",
    "Vamos registra a tabela no spark para ficar disponível para execução de querys\n",
    "\n",
    "    banco.registerTempTable(\"jobs\")\n",
    "    contexto.sql('Select * from jobs').show()\n",
    "    contexto.sql('Select *  from jobs order by salario_max DESC limit 1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41508f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91802778",
   "metadata": {},
   "source": [
    "### Criar um dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa1fb39",
   "metadata": {},
   "source": [
    "A variável `jobs` é nosso dataframe\n",
    "\n",
    "    jobs = contexto.sql(\"select * from jobs\") \n",
    "    jobs.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d71fa5",
   "metadata": {},
   "source": [
    "### Alguns comandos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c2b2a4",
   "metadata": {},
   "source": [
    "  \n",
    "    jobs.show()\n",
    "    jobs.printSchema()\n",
    "    jobs.select('job_title').show()\n",
    "    jobs.select('job_title', 'salario_max').show()\n",
    "    jobs.select('salario_max').distinct().show()\n",
    "    jobs.select('salario_max').distinct().count().show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0c74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c5dadc",
   "metadata": {},
   "source": [
    "# Iniciando o pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d2c4b",
   "metadata": {},
   "source": [
    "Para instalar `pyspark` localmente, execute em uma célula:\n",
    "\n",
    "    pip install pyspark\n",
    "    \n",
    "    \n",
    "**ATENÇÂO:** Se a célula abaixo falhar, pode ser necessário instalar o Java na sua máquina e reiniciar o computador!\n",
    "\n",
    "[Download Java para Windows](https://www.java.com/pt-BR/download/ie_manual.jsp?locale=pt_BR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b17462c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/zgiuliana/anaconda3/lib/python3.7/site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in /home/zgiuliana/anaconda3/lib/python3.7/site-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75468447",
   "metadata": {},
   "source": [
    "Para que o pyspark funcione, é preciso criar e configurar um ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af76a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:32:47.920759Z",
     "start_time": "2021-08-27T19:32:44.211252Z"
    }
   },
   "outputs": [],
   "source": [
    "# importar as funções\n",
    "from pyspark import sql, SparkContext, HiveContext\n",
    "\n",
    "# criar o sparkcontext\n",
    "sc = SparkContext()\n",
    "\n",
    "# criar a sessão spark\n",
    "spark = sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb2a6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:34:36.272428Z",
     "start_time": "2021-08-27T19:34:36.256827Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-30a7a72c866c>:5 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-128685fdfb6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# criar o sparkcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    345\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 347\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-30a7a72c866c>:5 "
     ]
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d6446a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:37:50.593026Z",
     "start_time": "2021-08-27T19:37:49.896326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.12:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f504732dad0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd7b1a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:38:31.161778Z",
     "start_time": "2021-08-27T19:38:31.140261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f5035b755d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e271eb",
   "metadata": {},
   "source": [
    "# Acessar arquivo csv com pyspark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfbd582",
   "metadata": {},
   "source": [
    "## Criar uma variável RDD a partir do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547a54a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:41:35.146934Z",
     "start_time": "2021-08-27T19:41:34.604012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,Public Accountant,4200.00,9000.00',\n",
       " '2,Accounting Manager,8200.00,16000.00',\n",
       " '3,Administration Assistant,3000.00,6000.00',\n",
       " '4,President,20000.00,40000.00',\n",
       " '5,Administration Vice President,15000.00,30000.00',\n",
       " '6,Accountant,4200.00,9000.00',\n",
       " '7,Finance Manager,8200.00,16000.00',\n",
       " '8,Human Resources Representative,4000.00,9000.00',\n",
       " '9,Programmer,4000.00,10000.00',\n",
       " '10,Marketing Manager,9000.00,15000.00',\n",
       " '11,Marketing Representative,4000.00,9000.00',\n",
       " '12,Public Relations Representative,4500.00,10500.00',\n",
       " '13,Purchasing Clerk,2500.00,5500.00',\n",
       " '14,Purchasing Manager,8000.00,15000.00',\n",
       " '15,Sales Manager,10000.00,20000.00',\n",
       " '16,Sales Representative,6000.00,12000.00',\n",
       " '17,Shipping Clerk,2500.00,5500.00',\n",
       " '18,Stock Clerk,2000.00,5000.00',\n",
       " '19,Stock Manager,5500.00,8500.00']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = sc.textFile('data/jobs.csv')\n",
    "jobs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee533b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41d588bb",
   "metadata": {},
   "source": [
    "## Acessar um arquivo csv via pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "363c3f27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:44:04.096217Z",
     "start_time": "2021-08-27T19:44:03.883378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+\n",
      "|country_id|country_name|region_id|\n",
      "+----------+------------+---------+\n",
      "|        AR|   Argentina|        2|\n",
      "|        AU|   Australia|        3|\n",
      "|        BE|     Belgium|        1|\n",
      "|        BR|      Brazil|        2|\n",
      "|        CA|      Canada|        2|\n",
      "|        CH| Switzerland|        1|\n",
      "|        CN|       China|        3|\n",
      "|        DE|     Germany|        1|\n",
      "|        DK|     Denmark|        1|\n",
      "|        EG|       Egypt|        4|\n",
      "|        FR|      France|        1|\n",
      "|        HK|    HongKong|        3|\n",
      "|        IL|      Israel|        4|\n",
      "|        IN|       India|        3|\n",
      "|        IT|       Italy|        1|\n",
      "|        JP|       Japan|        3|\n",
      "|        KW|      Kuwait|        4|\n",
      "|        MX|      Mexico|        2|\n",
      "|        NG|     Nigeria|        4|\n",
      "|        NL| Netherlands|        1|\n",
      "+----------+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ler tabela countries\n",
    "countries = spark.read.csv('data/countries.csv', header=True)\n",
    "countries.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259142b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "777cbcb3",
   "metadata": {},
   "source": [
    "## Adicionar headers quando não estão presentes no arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b43a457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:44:49.922493Z",
     "start_time": "2021-08-27T19:44:49.639837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+--------+\n",
      "|_c0|                 _c1|     _c2|     _c3|\n",
      "+---+--------------------+--------+--------+\n",
      "|  1|   Public Accountant| 4200.00| 9000.00|\n",
      "|  2|  Accounting Manager| 8200.00|16000.00|\n",
      "|  3|Administration As...| 3000.00| 6000.00|\n",
      "|  4|           President|20000.00|40000.00|\n",
      "|  5|Administration Vi...|15000.00|30000.00|\n",
      "|  6|          Accountant| 4200.00| 9000.00|\n",
      "|  7|     Finance Manager| 8200.00|16000.00|\n",
      "|  8|Human Resources R...| 4000.00| 9000.00|\n",
      "|  9|          Programmer| 4000.00|10000.00|\n",
      "| 10|   Marketing Manager| 9000.00|15000.00|\n",
      "| 11|Marketing Represe...| 4000.00| 9000.00|\n",
      "| 12|Public Relations ...| 4500.00|10500.00|\n",
      "| 13|    Purchasing Clerk| 2500.00| 5500.00|\n",
      "| 14|  Purchasing Manager| 8000.00|15000.00|\n",
      "| 15|       Sales Manager|10000.00|20000.00|\n",
      "| 16|Sales Representative| 6000.00|12000.00|\n",
      "| 17|      Shipping Clerk| 2500.00| 5500.00|\n",
      "| 18|         Stock Clerk| 2000.00| 5000.00|\n",
      "| 19|       Stock Manager| 5500.00| 8500.00|\n",
      "+---+--------------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ler arquivo jobs\n",
    "jobs = spark.read.csv('data/jobs.csv')\n",
    "jobs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5cb870a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:54:02.845799Z",
     "start_time": "2021-08-27T19:54:02.677700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+-----------+\n",
      "|indice|           job_title|salario_min|salario_max|\n",
      "+------+--------------------+-----------+-----------+\n",
      "|     1|   Public Accountant|     4200.0|     9000.0|\n",
      "|     2|  Accounting Manager|     8200.0|    16000.0|\n",
      "|     3|Administration As...|     3000.0|     6000.0|\n",
      "|     4|           President|    20000.0|    40000.0|\n",
      "|     5|Administration Vi...|    15000.0|    30000.0|\n",
      "|     6|          Accountant|     4200.0|     9000.0|\n",
      "|     7|     Finance Manager|     8200.0|    16000.0|\n",
      "|     8|Human Resources R...|     4000.0|     9000.0|\n",
      "|     9|          Programmer|     4000.0|    10000.0|\n",
      "|    10|   Marketing Manager|     9000.0|    15000.0|\n",
      "|    11|Marketing Represe...|     4000.0|     9000.0|\n",
      "|    12|Public Relations ...|     4500.0|    10500.0|\n",
      "|    13|    Purchasing Clerk|     2500.0|     5500.0|\n",
      "|    14|  Purchasing Manager|     8000.0|    15000.0|\n",
      "|    15|       Sales Manager|    10000.0|    20000.0|\n",
      "|    16|Sales Representative|     6000.0|    12000.0|\n",
      "|    17|      Shipping Clerk|     2500.0|     5500.0|\n",
      "|    18|         Stock Clerk|     2000.0|     5000.0|\n",
      "|    19|       Stock Manager|     5500.0|     8500.0|\n",
      "+------+--------------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importar arquivos de suporte\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, FloatType\n",
    "\n",
    "# criar schema\n",
    "schema_ = StructType() \\\n",
    "        .add('indice', IntegerType(), True) \\\n",
    "        .add('job_title', StringType(), True) \\\n",
    "        .add('salario_min', FloatType(), True) \\\n",
    "        .add('salario_max', FloatType(), True)\n",
    "\n",
    "# ler o arquivo\n",
    "df = spark.read.csv('data/jobs.csv', schema=schema_)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f42590",
   "metadata": {},
   "outputs": [],
   "source": [
    "Intervalo. Voltamos 17:04!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970806bb",
   "metadata": {},
   "source": [
    "# Analíses com pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575bd7d",
   "metadata": {},
   "source": [
    "## select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0681acb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:25.251662Z",
     "start_time": "2021-08-27T18:09:25.119531Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           job_title|\n",
      "+--------------------+\n",
      "|   Public Accountant|\n",
      "|  Accounting Manager|\n",
      "|Administration As...|\n",
      "|           President|\n",
      "|Administration Vi...|\n",
      "|          Accountant|\n",
      "|     Finance Manager|\n",
      "|Human Resources R...|\n",
      "|          Programmer|\n",
      "|   Marketing Manager|\n",
      "|Marketing Represe...|\n",
      "|Public Relations ...|\n",
      "|    Purchasing Clerk|\n",
      "|  Purchasing Manager|\n",
      "|       Sales Manager|\n",
      "|Sales Representative|\n",
      "|      Shipping Clerk|\n",
      "|         Stock Clerk|\n",
      "|       Stock Manager|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('job_title').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4845d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aba7cf3",
   "metadata": {},
   "source": [
    "## filter e/ou where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "304f7620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:28.839350Z",
     "start_time": "2021-08-27T18:09:28.655761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+-----------+\n",
      "|indice|           job_title|salario_min|salario_max|\n",
      "+------+--------------------+-----------+-----------+\n",
      "|     4|           President|    20000.0|    40000.0|\n",
      "|     5|Administration Vi...|    15000.0|    30000.0|\n",
      "+------+--------------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.salario_min>=15000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a56a17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+-----------+\n",
      "|indice|           job_title|salario_min|salario_max|\n",
      "+------+--------------------+-----------+-----------+\n",
      "|     1|   Public Accountant|     4200.0|     9000.0|\n",
      "|     2|  Accounting Manager|     8200.0|    16000.0|\n",
      "|     3|Administration As...|     3000.0|     6000.0|\n",
      "|     6|          Accountant|     4200.0|     9000.0|\n",
      "|     7|     Finance Manager|     8200.0|    16000.0|\n",
      "|     8|Human Resources R...|     4000.0|     9000.0|\n",
      "|     9|          Programmer|     4000.0|    10000.0|\n",
      "|    10|   Marketing Manager|     9000.0|    15000.0|\n",
      "|    11|Marketing Represe...|     4000.0|     9000.0|\n",
      "|    12|Public Relations ...|     4500.0|    10500.0|\n",
      "|    13|    Purchasing Clerk|     2500.0|     5500.0|\n",
      "|    14|  Purchasing Manager|     8000.0|    15000.0|\n",
      "|    15|       Sales Manager|    10000.0|    20000.0|\n",
      "|    16|Sales Representative|     6000.0|    12000.0|\n",
      "|    17|      Shipping Clerk|     2500.0|     5500.0|\n",
      "|    18|         Stock Clerk|     2000.0|     5000.0|\n",
      "|    19|       Stock Manager|     5500.0|     8500.0|\n",
      "+------+--------------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.salario_min<15000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5034fae0-cb13-49f4-82cc-936d981a50d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+-----------+\n",
      "|indice|           job_title|salario_min|salario_max|\n",
      "+------+--------------------+-----------+-----------+\n",
      "|     4|           President|    20000.0|    40000.0|\n",
      "|     5|Administration Vi...|    15000.0|    30000.0|\n",
      "+------+--------------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_min=df.filter(df.salario_min>=15000)\n",
    "df_min.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62f82d9c-5068-4afe-b8e6-9b4259d7145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           job_title|\n",
      "+--------------------+\n",
      "|Administration Vi...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_min.select('job_title').where(df.salario_min==15000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fca223",
   "metadata": {},
   "source": [
    "## sum, min, max, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447915b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:13:32.969036Z",
     "start_time": "2021-08-27T18:13:32.823552Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a833931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53f739d3",
   "metadata": {},
   "source": [
    "## agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704c895",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:13:09.840784Z",
     "start_time": "2021-08-27T18:13:09.710812Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665bbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc4f5cd",
   "metadata": {},
   "source": [
    "## [join](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.join.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29035fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:16:23.920746Z",
     "start_time": "2021-08-27T18:16:23.732164Z"
    }
   },
   "outputs": [],
   "source": [
    "# ler tabela employees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4d373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:30:24.106507Z",
     "start_time": "2021-08-27T18:30:23.872018Z"
    }
   },
   "outputs": [],
   "source": [
    "# join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb70e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd0751c1",
   "metadata": {},
   "source": [
    "## toPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60d921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
