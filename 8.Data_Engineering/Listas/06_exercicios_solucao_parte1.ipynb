{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6160dadb",
   "metadata": {},
   "source": [
    "# Data Warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3cec5e",
   "metadata": {},
   "source": [
    "## Tabelas externas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af713d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T17:54:00.846828Z",
     "start_time": "2021-08-27T17:54:00.841942Z"
    }
   },
   "source": [
    "Para cada tabela, execute os passos abaixo trocando o nomes do arquivo/tabela onde necessário:\n",
    "\n",
    "1. No terminal, execute:\n",
    "    1. hdfs dfs -mkdir /user/hive/hr/**jobs**\n",
    "    1. hdfs dfs -put Documents/hr_data/**jobs.csv** /user/hive/hr/**jobs**\n",
    "\n",
    "\n",
    "2. No beeline:\n",
    "\n",
    "    create external table **jobs( indice int, job_title string, salario_min float, salario_max float )**  \n",
    "    row format delimited fields terminated by ',' lines terminated by '\\n' stored as textfile   \n",
    "    location '/user/hive/hr/**jobs**';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb190a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09965166",
   "metadata": {},
   "source": [
    "## Tabelas internas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a93ec",
   "metadata": {},
   "source": [
    "1. No terminal, execute (isso moverá todas as tabelas de uma vez):\n",
    "    1. hdfs dfs -mkdir /user/hive/hr\n",
    "    1. hdfs dfs -put Documents/hr_data/\\* /user/hive/hr\n",
    "    \n",
    "    \n",
    "2. No beeline (**note como tratar as tabelas com headers e com ',' no campo de texto - também funciona pra tabela interna**):\n",
    "\n",
    "    create table jobs( indice int, job_title string, salario_min float, salario_max float )   \n",
    "    row format delimited fields terminated by ',' lines terminated by '\\n' stored as textfile ;  \n",
    "    load data inpath '/user/hive/data_hr/jobs.csv' overwrite into table jobs;  \n",
    "\n",
    "    create table employees( employee_id int, first_name string ,last_name string ,email string, phone_number  string, hire_date date,job_id int, salary float, manager_id int, department_id int)   \n",
    "    row format delimited fields terminated by ',' lines terminated by '\\n' stored as textfile   \n",
    "    tblproperties (\"skip.header.line.count\"=\"1\");  \n",
    "    load data inpath '/user/hive/data_hr/employees.csv' overwrite into table employees;  \n",
    "\n",
    "    create table countries( country_id string, country_name string,region_id string)   \n",
    "    row format delimited fields terminated by ',' lines terminated by '\\n' stored as textfile   \n",
    "    tblproperties (\"skip.header.line.count\"=\"1\");  \n",
    "    load data inpath '/user/hive/data_hr/countries.csv' overwrite into table countries;  \n",
    "\n",
    "    create table departments( department_id int, department_name string, location_id int)   \n",
    "    row format delimited fields terminated by ',' lines terminated by '\\n' stored as textfile   \n",
    "    tblproperties (\"skip.header.line.count\"=\"1\");  \n",
    "    load data inpath '/user/hive/data_hr/departments.csv' overwrite into table departments;  \n",
    "\n",
    "    create table dependents( dependent_id int ,first_name string, last_name string, relationship string, employee_id int)   \n",
    "    row format delimited fields terminated by ',' lines terminated by '\\n' stored as textfile   \n",
    "    tblproperties (\"skip.header.line.count\"=\"1\");  \n",
    "    load data inpath '/user/hive/data_hr/dependents.csv' overwrite into table dependents;  \n",
    "\n",
    "    create table locations( location_id int, street_name string, postal_code string, city string, country_id string)   \n",
    "    ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'  \n",
    "    WITH SERDEPROPERTIES (  \n",
    "       \"separatorChar\" = \",\",  \n",
    "       \"quoteChar\"     = \"\\\"\"  \n",
    "    );    \n",
    "    load data inpath '/user/hive/data_hr/locations.csv' overwrite into table locations;  \n",
    "\n",
    "    create table regions( region_id int, region string)   \n",
    "    row format delimited fields terminated by ',' lines terminated by '\\n' stored as textfile;  \n",
    "    load data inpath '/user/hive/data_hr/regions.csv' overwrite into table regions;  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab4d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
